#!/Users/cehwang/miniconda3/bin/python3
"""
LP ì‹ ìƒí’ˆ ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ (Yes24 + Aladin + Ktown4u)
ìƒˆ ìƒí’ˆì´ ë“±ë¡ë˜ë©´ Discordë¡œ ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.
Seleniumì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤.
"""

import requests
from bs4 import BeautifulSoup
import json
import os
import re
from datetime import datetime, timezone
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# ì„¤ì •
SITES = {
    "yes24": {
        "name": "Yes24",
        "url": "https://www.yes24.com/Product/Category/Display/003001033001",
        "color": 0x00D4AA,  # ì´ˆë¡ìƒ‰
    },
    "aladin": {
        "name": "ì•Œë¼ë”˜",
        "url": "https://www.aladin.co.kr/shop/wbrowse.aspx?BrowseTarget=List&ViewRowsCount=25&ViewType=Detail&PublishMonth=0&SortOrder=6&page=1&Stockstatus=1&PublishDay=84&CID=86800&SearchOption=",
        "color": 0xFFD700,  # ë…¸ë€ìƒ‰ (ê³¨ë“œ)
    },
    "ktown4u": {
        "name": "Ktown4u",
        "url": "https://kr.ktown4u.com/searchList?goodsTextSearch=lp&goodsSearch=newgoods",
        "color": 0xFF6B6B,  # ë¹¨ê°„ìƒ‰
    },
}

DISCORD_WEBHOOK_URL = "https://discordapp.com/api/webhooks/1464577763527889137/crrzuov6ADoIoNcrJ5-jCK723zkXmjaKovNOL5WprbGlTVDjrhIKIJJcvr0RpkqDeOkx"
DATA_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "products.json")


def load_saved_products():
    """ì €ì¥ëœ ìƒí’ˆ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            # ê¸°ì¡´ í˜•ì‹ -> ìƒˆ í˜•ì‹ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
            if data and not any(key in data for key in SITES.keys()):
                print(f"[{datetime.now()}] ë°ì´í„° í˜•ì‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
                return {"yes24": data, "aladin": {}, "ktown4u": {}}
            # ìƒˆ ì‚¬ì´íŠ¸ ì¶”ê°€ ì‹œ í‚¤ ì´ˆê¸°í™”
            for site_key in SITES.keys():
                if site_key not in data:
                    data[site_key] = {}
            return data
    return {site: {} for site in SITES.keys()}


def save_products(products):
    """ìƒí’ˆ ëª©ë¡ ì €ì¥"""
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(products, f, ensure_ascii=False, indent=2)


def create_driver():
    """Chrome WebDriver ìƒì„±"""
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    # navigator.webdriver ìˆ¨ê¸°ê¸°
    driver.execute_cdp_cmd(
        "Page.addScriptToEvaluateOnNewDocument",
        {"source": 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'},
    )

    return driver


def fetch_yes24_products(driver, saved_products, is_first_run):
    """Yes24ì—ì„œ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì‹ ìƒí’ˆìˆœ + ë“±ë¡ì¼ìˆœ) - ì¦‰ì‹œ ì•Œë¦¼"""
    products = {}
    site_saved = saved_products.get("yes24", {})

    def parse_and_notify():
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ìƒí’ˆ íŒŒì‹± ë° ì¦‰ì‹œ ì•Œë¦¼"""
        soup = BeautifulSoup(driver.page_source, "html.parser")
        page_products = {}

        for item in soup.select("li[data-goods-no]"):
            try:
                product_id = item.get("data-goods-no")
                if not product_id:
                    continue

                title_tag = item.select_one("a.gd_name")
                title = title_tag.get_text(strip=True) if title_tag else ""

                price = ""
                price_input = item.select_one("input[name='ORD_GOODS_OPT']")
                if price_input:
                    try:
                        price_data = json.loads(price_input.get("value", "{}"))
                        sale_price = price_data.get("salePrice", 0)
                        if sale_price:
                            price = f"{int(sale_price):,}ì›"
                    except:
                        pass

                if not price:
                    price_tag = item.select_one("em.yes_b")
                    if price_tag:
                        price = price_tag.get_text(strip=True) + "ì›"

                img_tag = item.select_one("img")
                img_url = ""
                if img_tag:
                    img_url = img_tag.get("data-original") or img_tag.get("src", "")
                    if img_url.startswith("//"):
                        img_url = "https:" + img_url

                # í’ˆì ˆ ì—¬ë¶€ í™•ì¸
                item_text = item.get_text()
                item_html = str(item).lower()
                is_soldout = (
                    "í’ˆì ˆ" in item_text
                    or "soldout" in item_html
                    or item.select_one('[class*="soldout"]') is not None
                )

                if product_id and title:
                    product = {
                        "title": title[:100],
                        "price": price,
                        "url": f"https://www.yes24.com/Product/Goods/{product_id}",
                        "image": img_url,
                        "soldout": is_soldout,
                    }
                    page_products[product_id] = product

                    # ì‹ ìƒí’ˆì´ë©´ ì¦‰ì‹œ ì•Œë¦¼
                    if product_id not in site_saved and product_id not in products:
                        if not is_first_run:
                            print(f"[{datetime.now()}] [Yes24] ì‹ ìƒí’ˆ ë°œê²¬! ì¦‰ì‹œ ì•Œë¦¼: {title[:50]}")
                            send_discord_notification("yes24", {product_id: product})
            except:
                continue

        return page_products

    try:
        url = SITES["yes24"]["url"]
        print(f"[{datetime.now()}] [Yes24] í˜ì´ì§€ ë¡œë“œ ì¤‘...")
        driver.get(url)

        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "li[data-goods-no]"))
        )

        # 1. ì‹ ìƒí’ˆìˆœ ì •ë ¬
        print(f"[{datetime.now()}] [Yes24] ì‹ ìƒí’ˆìˆœ ì •ë ¬ í´ë¦­...")
        sort_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "a[data-search-value='RECENT']"))
        )
        sort_button.click()

        time.sleep(2)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "li[data-goods-no]"))
        )

        recent_products = parse_and_notify()
        print(f"[{datetime.now()}] [Yes24] ì‹ ìƒí’ˆìˆœ: {len(recent_products)}ê°œ")
        products.update(recent_products)

        # 2. ë“±ë¡ì¼ìˆœ ì •ë ¬
        print(f"[{datetime.now()}] [Yes24] ë“±ë¡ì¼ìˆœ ì •ë ¬ í´ë¦­...")
        sort_button = WebDriverWait(driver, 10).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "a[data-search-value='REG_DTS']"))
        )
        sort_button.click()

        time.sleep(2)
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "li[data-goods-no]"))
        )

        new_products = parse_and_notify()
        print(f"[{datetime.now()}] [Yes24] ë“±ë¡ì¼ìˆœ: {len(new_products)}ê°œ")

        # ë“±ë¡ì¼ìˆœì—ì„œ ìƒˆë¡œ ë°œê²¬ëœ ìƒí’ˆ ì¶”ê°€
        for pid, prod in new_products.items():
            if pid not in products:
                products[pid] = prod

        return products

    except Exception as e:
        print(f"[{datetime.now()}] [Yes24] ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def fetch_aladin_products(saved_products, is_first_run):
    """ì•Œë¼ë”˜ì—ì„œ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì¶œì‹œì¼ìˆœ + ë“±ë¡ì¼ìˆœ) - requests ì‚¬ìš©ìœ¼ë¡œ ë¹ ë¥¸ ì¡°íšŒ"""
    products = {}
    site_saved = saved_products.get("aladin", {})

    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9',
    }

    def parse_and_notify(html):
        """HTMLì—ì„œ ìƒí’ˆ íŒŒì‹± ë° ì¦‰ì‹œ ì•Œë¦¼"""
        soup = BeautifulSoup(html, "html.parser")
        page_products = {}

        for box in soup.select("div.ss_book_box"):
            try:
                title_link = box.select_one("a.bo3")
                if not title_link:
                    title_link = box.select_one('a[href*="ItemId="]')

                if not title_link:
                    continue

                href = title_link.get("href", "")
                match = re.search(r"ItemId=(\d+)", href)
                if not match:
                    continue

                product_id = match.group(1)
                title = title_link.get_text(strip=True)

                price_tag = box.select_one("span.ss_p2")
                price = price_tag.get_text(strip=True) if price_tag else ""

                img_tag = box.select_one('img[src*="image.aladin.co.kr"]')
                img_url = ""
                if img_tag:
                    img_url = img_tag.get("src", "")
                    img_url = img_url.replace("coversum", "cover200")

                # í’ˆì ˆ ì—¬ë¶€ í™•ì¸
                box_text = box.get_text()
                is_soldout = "í’ˆì ˆ" in box_text or "ì ˆíŒ" in box_text

                if product_id and title:
                    product = {
                        "title": title[:100],
                        "price": price,
                        "url": f"https://www.aladin.co.kr/shop/wproduct.aspx?ItemId={product_id}",
                        "image": img_url,
                        "soldout": is_soldout,
                    }
                    page_products[product_id] = product

                    # ì‹ ìƒí’ˆì´ë©´ ì¦‰ì‹œ ì•Œë¦¼
                    if product_id not in site_saved and product_id not in products:
                        if not is_first_run:
                            print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ì‹ ìƒí’ˆ ë°œê²¬! ì¦‰ì‹œ ì•Œë¦¼: {title[:50]}")
                            send_discord_notification("aladin", {product_id: product})
            except:
                continue

        return page_products

    try:
        base_url = "https://www.aladin.co.kr/shop/wbrowse.aspx?BrowseTarget=List&ViewRowsCount=25&ViewType=Detail&PublishMonth=0&page=1&Stockstatus=1&PublishDay=84&CID=86800&SearchOption="

        # 1. ì¶œì‹œì¼ìˆœ (SortOrder=5)
        print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ì¶œì‹œì¼ìˆœ ì¡°íšŒ ì¤‘...")
        response = requests.get(base_url + "&SortOrder=5", headers=headers, timeout=10)
        release_products = parse_and_notify(response.text)
        print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ì¶œì‹œì¼ìˆœ: {len(release_products)}ê°œ")
        products.update(release_products)

        # 2. ë“±ë¡ì¼ìˆœ (SortOrder=6)
        print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ë“±ë¡ì¼ìˆœ ì¡°íšŒ ì¤‘...")
        response = requests.get(base_url + "&SortOrder=6", headers=headers, timeout=10)
        register_products = parse_and_notify(response.text)
        print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ë“±ë¡ì¼ìˆœ: {len(register_products)}ê°œ")

        # ë“±ë¡ì¼ìˆœì—ì„œ ìƒˆë¡œ ë°œê²¬ëœ ìƒí’ˆ ì¶”ê°€
        for pid, prod in register_products.items():
            if pid not in products:
                products[pid] = prod

        return products

    except Exception as e:
        print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def fetch_ktown4u_products(driver, saved_products, is_first_run):
    """Ktown4uì—ì„œ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° - ì¦‰ì‹œ ì•Œë¦¼ (ìµœì í™”)"""
    site_saved = saved_products.get("ktown4u", {})

    try:
        url = SITES["ktown4u"]["url"]
        print(f"[{datetime.now()}] [Ktown4u] í˜ì´ì§€ ë¡œë“œ ì¤‘...")
        driver.get(url)

        # ìƒí’ˆì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 10ì´ˆ)
        WebDriverWait(driver, 10).until(
            lambda d: len(d.find_elements(By.CSS_SELECTOR, 'a[href*="/iteminfo?"]')) > 5
        )

        # ìŠ¤í¬ë¡¤í•´ì„œ ë” ë§ì€ ìƒí’ˆ ë¡œë“œ (ìµœì í™”: 3íšŒë¡œ ì¶•ì†Œ, ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•)
        for _ in range(3):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.8)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        products = {}

        # ìƒí’ˆ ë§í¬ ì°¾ê¸°
        product_links = soup.select('a[href*="/iteminfo?"]')

        for link in product_links:
            try:
                href = link.get("href", "")
                match = re.search(r"goods_no=(\d+)", href)
                if not match:
                    continue

                product_id = match.group(1)
                if product_id in products:
                    continue

                # ì´ë¯¸ì§€ì™€ ì œëª© ì°¾ê¸°
                img = link.select_one("img")
                if not img:
                    continue

                title = img.get("alt", "")
                if not title or "LP" not in title.upper():
                    continue

                img_url = img.get("src", "")

                # ê°€ê²© ì°¾ê¸°
                link_text = link.get_text()
                price_match = re.search(r"KRW\s*([\d,]+)", link_text)
                price = ""
                if price_match:
                    price = price_match.group(1) + "ì›"

                # í’ˆì ˆ ì—¬ë¶€ í™•ì¸
                is_soldout = "í’ˆì ˆ" in link_text

                product = {
                    "title": title[:100],
                    "price": price,
                    "url": f"https://kr.ktown4u.com/iteminfo?goods_no={product_id}",
                    "image": img_url.replace("/thumbnail/", "/detail/") if img_url else "",
                    "soldout": is_soldout,
                }
                products[product_id] = product

                # ì‹ ìƒí’ˆì´ë©´ ì¦‰ì‹œ ì•Œë¦¼
                if product_id not in site_saved:
                    if not is_first_run:
                        print(f"[{datetime.now()}] [Ktown4u] ì‹ ìƒí’ˆ ë°œê²¬! ì¦‰ì‹œ ì•Œë¦¼: {title[:50]}")
                        send_discord_notification("ktown4u", {product_id: product})
            except:
                continue

        return products

    except Exception as e:
        print(f"[{datetime.now()}] [Ktown4u] ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def send_discord_notification(site_key, new_products):
    """Discordë¡œ ìƒˆ ìƒí’ˆ ì•Œë¦¼ ë³´ë‚´ê¸°"""
    site = SITES[site_key]

    for product_id, product in new_products.items():
        # í’ˆì ˆ ì—¬ë¶€ì— ë”°ë¼ íƒ€ì´í‹€ ë³€ê²½
        is_soldout = product.get("soldout", False)
        title_prefix = "ğŸµ ìƒˆ LP ë“±ë¡!"
        if is_soldout:
            title_prefix = "ğŸµ ìƒˆ LP ë“±ë¡! [í’ˆì ˆ]"

        embed = {
            "embeds": [
                {
                    "title": f"{title_prefix} [{site['name']}]",
                    "description": product["title"],
                    "url": product["url"],
                    "color": 0x808080 if is_soldout else site["color"],  # í’ˆì ˆì´ë©´ íšŒìƒ‰
                    "fields": [],
                    "footer": {"text": f"{site['name']} LP"},
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                }
            ]
        }

        if product["price"]:
            price_display = product["price"]
            if is_soldout:
                price_display = f"~~{product['price']}~~ (í’ˆì ˆ)"
            embed["embeds"][0]["fields"].append(
                {"name": "ê°€ê²©", "value": price_display, "inline": True}
            )

        if product["image"]:
            embed["embeds"][0]["thumbnail"] = {"url": product["image"]}

        try:
            response = requests.post(DISCORD_WEBHOOK_URL, json=embed, timeout=10)
            if response.status_code == 204:
                print(f"[{datetime.now()}] [{site['name']}] ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ: {product['title']}")
            else:
                print(f"[{datetime.now()}] [{site['name']}] ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            time.sleep(0.5)
        except Exception as e:
            print(f"[{datetime.now()}] [{site['name']}] Discord ì „ì†¡ ì˜¤ë¥˜: {e}")


def main():
    print(f"[{datetime.now()}] LP ëª¨ë‹ˆí„°ë§ ì‹œì‘ (Yes24 + ì•Œë¼ë”˜ + Ktown4u)...")
    start_time = time.time()

    saved_products = load_saved_products()
    is_first_run = all(not saved_products.get(site, {}) for site in SITES.keys())

    results = {}
    driver = None

    try:
        # ë³‘ë ¬ ì‹¤í–‰: ì•Œë¼ë”˜(requests)ê³¼ Selenium ì‘ì—… ë™ì‹œ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=2) as executor:
            # ì•Œë¼ë”˜ì€ requestsë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            aladin_future = executor.submit(fetch_aladin_products, saved_products, is_first_run)

            # Selenium ì‘ì—… (Yes24 + Ktown4u)ëŠ” ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ìˆœì°¨ ì‹¤í–‰
            driver = create_driver()

            # Yes24 ì¡°íšŒ
            yes24_products = fetch_yes24_products(driver, saved_products, is_first_run)
            if yes24_products:
                results["yes24"] = yes24_products
                print(f"[{datetime.now()}] [Yes24] ì¡°íšŒëœ ìƒí’ˆ: {len(yes24_products)}ê°œ")

            # Ktown4u ì¡°íšŒ
            ktown4u_products = fetch_ktown4u_products(driver, saved_products, is_first_run)
            if ktown4u_products:
                results["ktown4u"] = ktown4u_products
                print(f"[{datetime.now()}] [Ktown4u] ì¡°íšŒëœ ìƒí’ˆ: {len(ktown4u_products)}ê°œ")

            # ì•Œë¼ë”˜ ê²°ê³¼ ìˆ˜ì§‘
            aladin_products = aladin_future.result()
            if aladin_products:
                results["aladin"] = aladin_products
                print(f"[{datetime.now()}] [ì•Œë¼ë”˜] ì¡°íšŒëœ ìƒí’ˆ: {len(aladin_products)}ê°œ")

        # ê²°ê³¼ ì €ì¥
        for site_key, current_products in results.items():
            site_saved = saved_products.get(site_key, {})
            saved_products[site_key] = {**site_saved, **current_products}

        save_products(saved_products)

        elapsed = time.time() - start_time
        print(f"[{datetime.now()}] ì´ ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")

        if is_first_run:
            print(f"[{datetime.now()}] ì²« ì‹¤í–‰ - ìƒí’ˆ ëª©ë¡ ì €ì¥ ì™„ë£Œ")
            total_count = sum(len(saved_products.get(s, {})) for s in SITES.keys())
            test_msg = {
                "content": f"âœ… LP ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤! (Yes24 + ì•Œë¼ë”˜ + Ktown4u)\ní˜„ì¬ ì´ {total_count}ê°œì˜ ìƒí’ˆì„ ì¶”ì  ì¤‘ì…ë‹ˆë‹¤."
            }
            try:
                requests.post(DISCORD_WEBHOOK_URL, json=test_msg, timeout=10)
            except:
                pass

    finally:
        if driver:
            driver.quit()


if __name__ == "__main__":
    main()
