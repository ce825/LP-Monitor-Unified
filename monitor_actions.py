#!/usr/bin/env python3
"""
LP í†µí•© ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸ (GitHub Actionsìš©)
ì‹ ìƒí’ˆ + ì¬ì…ê³ ë¥¼ í•œ ë²ˆì— ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
Yes24 + Aladin + Ktown4u
"""

import requests
from bs4 import BeautifulSoup
import json
import os
import re
import random
from datetime import datetime, timezone
import time
from concurrent.futures import ThreadPoolExecutor

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException

# ì„¤ì •
SITES = {
    "yes24": {
        "name": "Yes24",
        "url": "https://www.yes24.com/Product/Category/Display/003001033001",
        "color": 0x00D4AA,
    },
    "aladin": {
        "name": "ì•Œë¼ë”˜",
        "url": "https://www.aladin.co.kr/shop/wbrowse.aspx?BrowseTarget=List&ViewRowsCount=25&ViewType=Detail&PublishMonth=0&SortOrder=6&page=1&Stockstatus=1&PublishDay=84&CID=86800&SearchOption=",
        "color": 0xFFD700,
    },
    "ktown4u": {
        "name": "Ktown4u",
        "url": "https://kr.ktown4u.com/searchList?goodsTextSearch=lp&goodsSearch=newgoods",
        "color": 0xFF6B6B,
    },
}

# Discord Webhooks (ì‹ ìƒí’ˆ/ì¬ì…ê³  ë¶„ë¦¬)
DISCORD_WEBHOOK_NEW = os.environ.get("DISCORD_WEBHOOK_NEW", "")
DISCORD_WEBHOOK_RESTOCK = os.environ.get("DISCORD_WEBHOOK_RESTOCK", "")
DATA_FILE = "products.json"


def load_saved_products():
    """ì €ì¥ëœ ìƒí’ˆ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if os.path.exists(DATA_FILE):
        with open(DATA_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            for site_key in SITES.keys():
                if site_key not in data:
                    data[site_key] = {}
            return data
    return {site: {} for site in SITES.keys()}


def save_products(products):
    """ìƒí’ˆ ëª©ë¡ ì €ì¥"""
    with open(DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(products, f, ensure_ascii=False, indent=2)


def create_driver():
    """Chrome WebDriver ìƒì„±"""
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument(
        "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)

    driver = webdriver.Chrome(options=chrome_options)
    driver.execute_cdp_cmd(
        "Page.addScriptToEvaluateOnNewDocument",
        {"source": 'Object.defineProperty(navigator, "webdriver", {get: () => undefined})'},
    )
    return driver


def get_first_product_id(driver):
    """í˜„ì¬ í˜ì´ì§€ì˜ ì²« ë²ˆì§¸ ìƒí’ˆ ID ê°€ì ¸ì˜¤ê¸°"""
    try:
        first_item = driver.find_element(By.CSS_SELECTOR, "li[data-goods-no]")
        return first_item.get_attribute("data-goods-no")
    except:
        return None


def click_sort_and_wait(driver, sort_value, sort_name, max_wait=10):
    """ì •ë ¬ ë²„íŠ¼ í´ë¦­ í›„ í˜ì´ì§€ ë³€ê²½ ëŒ€ê¸°"""
    try:
        # í˜„ì¬ ì²« ë²ˆì§¸ ìƒí’ˆ ID ì €ì¥
        old_first_id = get_first_product_id(driver)
        print(f"[Yes24] {sort_name} ì •ë ¬ í´ë¦­ (í˜„ì¬ ì²« ìƒí’ˆ: {old_first_id})")

        # JavaScriptë¡œ ì •ë ¬ ë²„íŠ¼ í´ë¦­
        driver.execute_script(f"""
            var btn = document.querySelector("a[data-search-value='{sort_value}']");
            if (btn) btn.click();
        """)

        # í˜ì´ì§€ ë‚´ìš©ì´ ë³€ê²½ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        start_time = time.time()
        while time.time() - start_time < max_wait:
            time.sleep(0.5)
            new_first_id = get_first_product_id(driver)
            if new_first_id and new_first_id != old_first_id:
                print(f"[Yes24] {sort_name} í˜ì´ì§€ ë³€ê²½ ê°ì§€ (ìƒˆ ì²« ìƒí’ˆ: {new_first_id})")
                time.sleep(1)  # ì¶”ê°€ ì•ˆì •í™” ëŒ€ê¸°
                return True

        # ë³€ê²½ ì•ˆ ë˜ë©´ ê·¸ëƒ¥ ëŒ€ê¸° í›„ ì§„í–‰
        print(f"[Yes24] {sort_name} í˜ì´ì§€ ë³€ê²½ ê°ì§€ ì‹¤íŒ¨, 5ì´ˆ ëŒ€ê¸° í›„ ì§„í–‰")
        time.sleep(5)
        return True

    except Exception as e:
        print(f"[Yes24] {sort_name} ì •ë ¬ ì‹¤íŒ¨: {e}")
        return False


def fetch_yes24_products(driver, saved_products, is_first_run):
    """Yes24ì—ì„œ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì‹ ìƒí’ˆìˆœ + ë“±ë¡ì¼ìˆœ + íŒë§¤ëŸ‰ìˆœ)"""
    products = {}
    site_key = "yes24"
    site_saved = saved_products.get(site_key, {})

    def parse_products_from_page():
        soup = BeautifulSoup(driver.page_source, "html.parser")
        page_products = {}

        for item in soup.select("li[data-goods-no]"):
            try:
                product_id = item.get("data-goods-no")
                if not product_id:
                    continue

                title_tag = item.select_one("a.gd_name")
                title = title_tag.get_text(strip=True) if title_tag else ""

                price = ""
                price_input = item.select_one("input[name='ORD_GOODS_OPT']")
                if price_input:
                    try:
                        price_data = json.loads(price_input.get("value", "{}"))
                        sale_price = price_data.get("salePrice", 0)
                        if sale_price:
                            price = f"{int(sale_price):,}ì›"
                    except:
                        pass

                if not price:
                    price_tag = item.select_one("em.yes_b")
                    if price_tag:
                        price = price_tag.get_text(strip=True) + "ì›"

                img_tag = item.select_one("img")
                img_url = ""
                if img_tag:
                    img_url = img_tag.get("data-original") or img_tag.get("src", "")
                    if img_url.startswith("//"):
                        img_url = "https:" + img_url

                # í’ˆì ˆ ì—¬ë¶€ í™•ì¸
                item_text = item.get_text()
                item_html = str(item).lower()
                is_soldout = (
                    "í’ˆì ˆ" in item_text
                    or "soldout" in item_html
                    or item.select_one('[class*="soldout"]') is not None
                )

                if product_id and title:
                    page_products[product_id] = {
                        "title": title[:100],
                        "price": price,
                        "url": f"https://www.yes24.com/Product/Goods/{product_id}",
                        "image": img_url,
                        "soldout": is_soldout,
                    }
            except:
                continue

        return page_products

    def process_products(page_products, label):
        """ìƒí’ˆ ì²˜ë¦¬ ë° ì•Œë¦¼ ì „ì†¡"""
        print(f"[Yes24] {label}: {len(page_products)}ê°œ")

        if not is_first_run:
            for pid, prod in page_products.items():
                if pid not in site_saved and pid not in products:
                    send_new_product_notification(site_key, {pid: prod})
                elif pid in site_saved and site_saved[pid].get("soldout") and not prod.get("soldout"):
                    send_restock_notification(site_key, {pid: prod})

        for pid, prod in page_products.items():
            if pid not in products:
                products[pid] = prod

    try:
        url = SITES["yes24"]["url"]
        print(f"[Yes24] í˜ì´ì§€ ë¡œë“œ ì¤‘...")
        driver.get(url)

        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "li[data-goods-no]"))
        )
        time.sleep(2)

        # 1. ì‹ ìƒí’ˆìˆœ ì •ë ¬
        if click_sort_and_wait(driver, "RECENT", "ì‹ ìƒí’ˆìˆœ"):
            recent_products = parse_products_from_page()
            process_products(recent_products, "ì‹ ìƒí’ˆìˆœ")

        # 2. ë“±ë¡ì¼ìˆœ ì •ë ¬
        if click_sort_and_wait(driver, "REG_DTS", "ë“±ë¡ì¼ìˆœ"):
            # ìŠ¤í¬ë¡¤í•´ì„œ ë” ë§ì€ ìƒí’ˆ ë¡œë“œ
            for _ in range(3):
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)
            new_products = parse_products_from_page()
            process_products(new_products, "ë“±ë¡ì¼ìˆœ")

        # 3. íŒë§¤ëŸ‰ìˆœ ì •ë ¬ (ì¬ì…ê³  ì²´í¬ìš©)
        if click_sort_and_wait(driver, "SALE_SCO", "íŒë§¤ëŸ‰ìˆœ"):
            sale_products = parse_products_from_page()
            process_products(sale_products, "íŒë§¤ëŸ‰ìˆœ")

        return products

    except Exception as e:
        print(f"[Yes24] ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return products if products else None


def fetch_aladin_products(saved_products, is_first_run):
    """ì•Œë¼ë”˜ì—ì„œ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì¶œì‹œì¼ìˆœ + ë“±ë¡ì¼ìˆœ + ë¦¬ë·°ìˆœ 2í˜ì´ì§€)"""
    products = {}
    site_key = "aladin"
    site_saved = saved_products.get(site_key, {})

    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9',
    }

    def parse_products_from_html(html):
        soup = BeautifulSoup(html, "html.parser")
        page_products = {}

        for box in soup.select("div.ss_book_box"):
            try:
                title_link = box.select_one("a.bo3")
                if not title_link:
                    title_link = box.select_one('a[href*="ItemId="]')

                if not title_link:
                    continue

                href = title_link.get("href", "")
                match = re.search(r"ItemId=(\d+)", href)
                if not match:
                    continue

                product_id = match.group(1)
                title = title_link.get_text(strip=True)

                price_tag = box.select_one("span.ss_p2")
                price = price_tag.get_text(strip=True) if price_tag else ""

                img_tag = box.select_one('img[src*="image.aladin.co.kr"]')
                img_url = ""
                if img_tag:
                    img_url = img_tag.get("src", "")
                    img_url = img_url.replace("coversum", "cover200")

                # í’ˆì ˆ ì—¬ë¶€ í™•ì¸
                box_text = box.get_text()
                is_soldout = "í’ˆì ˆ" in box_text or "ì ˆíŒ" in box_text

                if product_id and title:
                    page_products[product_id] = {
                        "title": title[:100],
                        "price": price,
                        "url": f"https://www.aladin.co.kr/shop/wproduct.aspx?ItemId={product_id}",
                        "image": img_url,
                        "soldout": is_soldout,
                    }
            except:
                continue

        return page_products

    def safe_request(url):
        """Rate limitì„ ê³ ë ¤í•œ ì•ˆì „í•œ ìš”ì²­"""
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 429:
                print(f"[ì•Œë¼ë”˜] Rate limit ê°ì§€, 5ì´ˆ ëŒ€ê¸°...")
                time.sleep(5)
                response = requests.get(url, headers=headers, timeout=10)
            return response
        except Exception as e:
            print(f"[ì•Œë¼ë”˜] ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None

    try:
        base_url = "https://www.aladin.co.kr/shop/wbrowse.aspx?BrowseTarget=List&ViewRowsCount=25&ViewType=Detail&PublishMonth=0&page=1&PublishDay=84&CID=86800&SearchOption="

        # 1. ì¶œì‹œì¼ìˆœ (SortOrder=5)
        print(f"[ì•Œë¼ë”˜] ì¶œì‹œì¼ìˆœ ì¡°íšŒ...")
        response = safe_request(base_url + "&SortOrder=5")
        if response:
            release_products = parse_products_from_html(response.text)
            print(f"[ì•Œë¼ë”˜] ì¶œì‹œì¼ìˆœ: {len(release_products)}ê°œ")

            # ì¦‰ì‹œ ì•Œë¦¼
            if not is_first_run:
                for pid, prod in release_products.items():
                    if pid not in site_saved and pid not in products:
                        send_new_product_notification(site_key, {pid: prod})
                    elif pid in site_saved and site_saved[pid].get("soldout") and not prod.get("soldout"):
                        send_restock_notification(site_key, {pid: prod})

            products.update(release_products)

        time.sleep(1)  # ìš”ì²­ ê°„ ë”œë ˆì´

        # 2. ë“±ë¡ì¼ìˆœ (SortOrder=6)
        print(f"[ì•Œë¼ë”˜] ë“±ë¡ì¼ìˆœ ì¡°íšŒ...")
        response = safe_request(base_url + "&SortOrder=6")
        if response:
            register_products = parse_products_from_html(response.text)
            print(f"[ì•Œë¼ë”˜] ë“±ë¡ì¼ìˆœ: {len(register_products)}ê°œ")

            # ì¦‰ì‹œ ì•Œë¦¼
            if not is_first_run:
                for pid, prod in register_products.items():
                    if pid not in site_saved and pid not in products:
                        send_new_product_notification(site_key, {pid: prod})
                    elif pid in site_saved and site_saved[pid].get("soldout") and not prod.get("soldout"):
                        send_restock_notification(site_key, {pid: prod})

            for pid, prod in register_products.items():
                if pid not in products:
                    products[pid] = prod

        time.sleep(1)  # ìš”ì²­ ê°„ ë”œë ˆì´

        # 3. ë¦¬ë·°ìˆœ (SortOrder=4) - ë‚ ì§œ í•„í„° ì—†ì´ 2í˜ì´ì§€ê¹Œì§€ (ì¬ì…ê³  ì²´í¬ìš©)
        review_base = "https://www.aladin.co.kr/shop/wbrowse.aspx?BrowseTarget=List&ViewRowsCount=25&ViewType=Detail&CID=86800&SortOrder=4"

        for page in [1, 2]:
            print(f"[ì•Œë¼ë”˜] ë¦¬ë·°ìˆœ {page}í˜ì´ì§€ ì¡°íšŒ...")
            response = safe_request(f"{review_base}&page={page}")
            if response:
                review_products = parse_products_from_html(response.text)
                print(f"[ì•Œë¼ë”˜] ë¦¬ë·°ìˆœ {page}í˜ì´ì§€: {len(review_products)}ê°œ")

                # ì¦‰ì‹œ ì•Œë¦¼ (ì¬ì…ê³ ìš©)
                if not is_first_run:
                    for pid, prod in review_products.items():
                        if pid not in site_saved and pid not in products:
                            send_new_product_notification(site_key, {pid: prod})
                        elif pid in site_saved and site_saved[pid].get("soldout") and not prod.get("soldout"):
                            send_restock_notification(site_key, {pid: prod})

                for pid, prod in review_products.items():
                    if pid not in products:
                        products[pid] = prod
            time.sleep(1)  # ìš”ì²­ ê°„ ë”œë ˆì´

        return products

    except Exception as e:
        print(f"[ì•Œë¼ë”˜] ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def fetch_ktown4u_products(driver, saved_products, is_first_run):
    """Ktown4uì—ì„œ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    site_key = "ktown4u"
    site_saved = saved_products.get(site_key, {})

    try:
        url = SITES["ktown4u"]["url"]
        print(f"[Ktown4u] í˜ì´ì§€ ë¡œë“œ ì¤‘...")
        driver.get(url)

        WebDriverWait(driver, 10).until(
            lambda d: len(d.find_elements(By.CSS_SELECTOR, 'a[href*="/iteminfo?"]')) > 5
        )

        # ìŠ¤í¬ë¡¤í•´ì„œ ë” ë§ì€ ìƒí’ˆ ë¡œë“œ
        for _ in range(3):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.8)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        products = {}

        product_links = soup.select('a[href*="/iteminfo?"]')

        for link in product_links:
            try:
                href = link.get("href", "")
                match = re.search(r"goods_no=(\d+)", href)
                if not match:
                    continue

                product_id = match.group(1)
                if product_id in products:
                    continue

                img = link.select_one("img")
                if not img:
                    continue

                title = img.get("alt", "")
                if not title or "LP" not in title.upper():
                    continue

                img_url = img.get("src", "")

                link_text = link.get_text()
                price_match = re.search(r"KRW\s*([\d,]+)", link_text)
                price = ""
                if price_match:
                    price = price_match.group(1) + "ì›"

                is_soldout = "í’ˆì ˆ" in link_text

                prod = {
                    "title": title[:100],
                    "price": price,
                    "url": f"https://kr.ktown4u.com/iteminfo?goods_no={product_id}",
                    "image": img_url.replace("/thumbnail/", "/detail/") if img_url else "",
                    "soldout": is_soldout,
                }

                # ì¦‰ì‹œ ì•Œë¦¼
                if not is_first_run:
                    if product_id not in site_saved:
                        send_new_product_notification(site_key, {product_id: prod})
                    elif site_saved[product_id].get("soldout") and not is_soldout:
                        send_restock_notification(site_key, {product_id: prod})

                products[product_id] = prod
            except:
                continue

        return products

    except Exception as e:
        print(f"[Ktown4u] ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def send_new_product_notification(site_key, new_products):
    """ì‹ ìƒí’ˆ ì•Œë¦¼ ì „ì†¡"""
    if not DISCORD_WEBHOOK_NEW:
        print("ì‹ ìƒí’ˆ Discord webhook URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    site = SITES[site_key]

    for product_id, product in new_products.items():
        is_soldout = product.get("soldout", False)
        title_prefix = "ğŸµ ìƒˆ LP ë“±ë¡!"
        if is_soldout:
            title_prefix = "ğŸµ ìƒˆ LP ë“±ë¡! [í’ˆì ˆ]"

        embed = {
            "embeds": [
                {
                    "title": f"{title_prefix} [{site['name']}]",
                    "description": product["title"],
                    "url": product["url"],
                    "color": 0x808080 if is_soldout else site["color"],
                    "fields": [],
                    "footer": {"text": f"{site['name']} LP"},
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                }
            ]
        }

        if product["price"]:
            price_display = product["price"]
            if is_soldout:
                price_display = f"~~{product['price']}~~ (í’ˆì ˆ)"
            embed["embeds"][0]["fields"].append(
                {"name": "ê°€ê²©", "value": price_display, "inline": True}
            )

        if product["image"]:
            embed["embeds"][0]["thumbnail"] = {"url": product["image"]}

        try:
            response = requests.post(DISCORD_WEBHOOK_NEW, json=embed, timeout=10)
            if response.status_code == 204:
                print(f"[{site['name']}] ì‹ ìƒí’ˆ ì•Œë¦¼ ì „ì†¡: {product['title'][:50]}")
            else:
                print(f"[{site['name']}] ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            time.sleep(0.5)
        except Exception as e:
            print(f"[{site['name']}] Discord ì „ì†¡ ì˜¤ë¥˜: {e}")


def send_restock_notification(site_key, restocked_products):
    """ì¬ì…ê³  ì•Œë¦¼ ì „ì†¡"""
    if not DISCORD_WEBHOOK_RESTOCK:
        print("ì¬ì…ê³  Discord webhook URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    site = SITES[site_key]

    for product_id, product in restocked_products.items():
        embed = {
            "embeds": [
                {
                    "title": f"ğŸ‰ LP ì¬ì…ê³ ! [{site['name']}]",
                    "description": product["title"],
                    "url": product["url"],
                    "color": site["color"],
                    "fields": [],
                    "footer": {"text": f"{site['name']} LP ì¬ì…ê³ "},
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                }
            ]
        }

        if product["price"]:
            embed["embeds"][0]["fields"].append(
                {"name": "ê°€ê²©", "value": product["price"], "inline": True}
            )

        if product["image"]:
            embed["embeds"][0]["thumbnail"] = {"url": product["image"]}

        try:
            response = requests.post(DISCORD_WEBHOOK_RESTOCK, json=embed, timeout=10)
            if response.status_code == 204:
                print(f"[{site['name']}] ì¬ì…ê³  ì•Œë¦¼ ì „ì†¡: {product['title'][:50]}")
            else:
                print(f"[{site['name']}] ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
            time.sleep(0.5)
        except Exception as e:
            print(f"[{site['name']}] Discord ì „ì†¡ ì˜¤ë¥˜: {e}")


def main():
    # ëœë¤ ë”œë ˆì´ (0~15ì´ˆ) - ë´‡ íŒ¨í„´ íšŒí”¼
    delay = random.randint(0, 15)
    print(f"[{datetime.now()}] ëœë¤ ë”œë ˆì´: {delay}ì´ˆ")
    time.sleep(delay)

    print(f"[{datetime.now()}] LP í†µí•© ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì‹ ìƒí’ˆ + ì¬ì…ê³ )...")
    start_time = time.time()

    saved_products = load_saved_products()
    is_first_run = all(not saved_products.get(site, {}) for site in SITES.keys())

    if is_first_run:
        print("ì²« ì‹¤í–‰ - ìƒí’ˆ ëª©ë¡ë§Œ ì €ì¥í•˜ê³  ì•Œë¦¼ì€ ë³´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    results = {}
    driver = None

    try:
        # ë³‘ë ¬ ì‹¤í–‰: ì•Œë¼ë”˜(requests)ê³¼ Selenium ì‘ì—… ë™ì‹œ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=2) as executor:
            # ì•Œë¼ë”˜ì€ requestsë¡œ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            aladin_future = executor.submit(fetch_aladin_products, saved_products, is_first_run)

            # Selenium ì‘ì—… (Yes24 + Ktown4u)
            driver = create_driver()

            yes24_products = fetch_yes24_products(driver, saved_products, is_first_run)
            if yes24_products:
                results["yes24"] = yes24_products

            ktown4u_products = fetch_ktown4u_products(driver, saved_products, is_first_run)
            if ktown4u_products:
                results["ktown4u"] = ktown4u_products

            # ì•Œë¼ë”˜ ê²°ê³¼ ìˆ˜ì§‘
            aladin_products = aladin_future.result()
            if aladin_products:
                results["aladin"] = aladin_products

        # ê²°ê³¼ ì§‘ê³„ (ì•Œë¦¼ì€ ì´ë¯¸ ì¦‰ì‹œ ì „ì†¡ë¨)
        for site_key, current_products in results.items():
            site = SITES[site_key]
            site_saved = saved_products.get(site_key, {})

            print(f"[{site['name']}] ì¡°íšŒ ì™„ë£Œ: {len(current_products)}ê°œ")

            # ìƒí’ˆ ë°ì´í„° ì—…ë°ì´íŠ¸
            for pid, prod in current_products.items():
                site_saved[pid] = prod
            saved_products[site_key] = site_saved

        # ì €ì¥
        save_products(saved_products)

        elapsed = time.time() - start_time
        print(f"[{datetime.now()}] ì™„ë£Œ - ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")

    finally:
        if driver:
            driver.quit()


if __name__ == "__main__":
    main()
